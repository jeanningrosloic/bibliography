\relax 
\catcode `"\active 
\citation{honnet2015atom}
\citation{fujisaki1998command}
\citation{schnell2018neural}
\citation{mallat1993matching}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{bohte2002error}
\citation{pfister2006optimal}
\citation{huh2018gradient}
\citation{tanaka2019recent}
\citation{lukovsevivcius2012reservoir}
\citation{maass2002real}
\citation{maass2011liquid}
\citation{maass2011liquid}
\citation{triefenbach2014large,triefenbach2010phoneme,ikeda2018short,zhao2018nonlinear}
\citation{zhang2015digital}
\citation{nicola2016supervised}
\citation{mohemmed2012span,mohemmed2013training}
\citation{schnell2018neural}
\citation{ponulak2006supervised,ponulak2010supervised}
\citation{ponulak2010supervised}
\citation{maass2002real}
\@writefile{toc}{\contentsline {section}{\numberline {2}Separation Property}{3}}
\citation{hourdakis2013use,wojcik2007liquid,grzyb2009model,wojcik2012electrical}
\citation{hourdakis2013use}
\citation{hourdakis2013use,grzyb2009model,maass2002real}
\citation{pipaextended}
\citation{dockendorf2009liquid}
\citation{bertschinger2004real,legenstein2007edge}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Liquid state distance $D_{u,v}$ as a function of time for different input distances $d(u,v)$. Liquid state distances are not proportional to input distances when VUV state inputs are not conected (top). Good proportionality is achieved with VUV state inputs connected (bottom) due to an earlier chaotic activation of the LSM (0-200 ms)}}{5}}
\newlabel{SPvuv}{{1}{5}}
\citation{maass2002real}
\citation{ponulak2006supervised,ponulak2010supervised}
\citation{mohemmed2012span,mohemmed2013training}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Slope $\alpha $ and residuals $r$ of the linear regression between liquid state distances $D_{u,v}$ and input distances $d(u,v)$, as well as standard deviation $\sigma $ averaged over the time interval [300 700] ms of SP experiment depending on the value of the LSM's density of connections $\lambda $.}}{6}}
\newlabel{SPlambda}{{2}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Approximation property}{6}}
\citation{hebb1949organization}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Weight update as a function of the presynaptic spike time for SPAN and ReSuMe learning rules. Postsynaptic spike time is $t_o = 10$ ms and teacher spike time is $t_d = 0$ ms}}{7}}
\newlabel{dw}{{3}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces RMS loss between teacher and output LF0 curves as a function of SPAN time constant $\tau $}}{8}}
\newlabel{SPANtheta}{{4}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Discussion}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Top: Reproduction of LF0 teacher signal (after substraction of a phrase component) with ReSuMe learning rule. Bottom: Reproduction of teacher spike trains (motor commands). Output spikes are red and teacher spikes blue for ten muscles}}{9}}
\newlabel{singleSampleR}{{5}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Same than Figure \ref  {singleSampleR} on a different sample with SPAN learning rule}}{9}}
\newlabel{singleSampleS}{{6}{9}}
\citation{ponulak2006generalization}
\citation{ohno1998effects}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Prediction performance of ReSuMe and SPAN learning rules as a function of the total number of samples used for the 6-fold cross-validation}}{10}}
\newlabel{multipleSample}{{7}{10}}
\@writefile{toc}{\contentsline {paragraph}{Motor commands}{10}}
\citation{pyle2018model}
\citation{legenstein2007edge}
\citation{vapnikn}
\citation{jaeger2004harnessing,sussillo2009generating,nicola2016supervised}
\citation{sussillo2009generating}
\@writefile{toc}{\contentsline {paragraph}{LSM generalization property}{11}}
\@writefile{toc}{\contentsline {paragraph}{Feedback}{11}}
\citation{nicola2016supervised}
\citation{karaiskos2008blizzard}
\citation{schnell2018neural}
\newlabel{methods}{{5}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Methods }{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Inputs}{12}}
\citation{maass2002real}
\citation{maass2002synapses}
\citation{markram1998differential}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Liquid State Machine}{13}}
\@writefile{toc}{\contentsline {paragraph}{Neuronal parameters}{13}}
\newlabel{IaF}{{3}{13}}
\@writefile{toc}{\contentsline {paragraph}{Connectivity structure}{13}}
\@writefile{toc}{\contentsline {paragraph}{Synaptic connections}{13}}
\citation{ponulak2010supervised}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Learning rules}{14}}
\@writefile{toc}{\contentsline {paragraph}{ReSuMe}{14}}
\citation{mohemmed2012span,mohemmed2013training}
\@writefile{toc}{\contentsline {paragraph}{SPAN}{15}}
\newlabel{SPAN}{{10}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Readout neurons}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Muscles}{15}}
\bibstyle{plain}
\bibdata{biblio}
\bibcite{bertschinger2004real}{{1}{}{{}}{{}}}
\bibcite{bohte2002error}{{2}{}{{}}{{}}}
\bibcite{dockendorf2009liquid}{{3}{}{{}}{{}}}
\bibcite{fujisaki1998command}{{4}{}{{}}{{}}}
\bibcite{grzyb2009model}{{5}{}{{}}{{}}}
\bibcite{hebb1949organization}{{6}{}{{}}{{}}}
\bibcite{honnet2015atom}{{7}{}{{}}{{}}}
\bibcite{hourdakis2013use}{{8}{}{{}}{{}}}
\bibcite{huh2018gradient}{{9}{}{{}}{{}}}
\bibcite{ikeda2018short}{{10}{}{{}}{{}}}
\bibcite{jaeger2004harnessing}{{11}{}{{}}{{}}}
\bibcite{karaiskos2008blizzard}{{12}{}{{}}{{}}}
\bibcite{legenstein2007edge}{{13}{}{{}}{{}}}
\bibcite{lukovsevivcius2012reservoir}{{14}{}{{}}{{}}}
\bibcite{maass2011liquid}{{15}{}{{}}{{}}}
\bibcite{maass2002synapses}{{16}{}{{}}{{}}}
\bibcite{maass2002real}{{17}{}{{}}{{}}}
\bibcite{mallat1993matching}{{18}{}{{}}{{}}}
\bibcite{markram1998differential}{{19}{}{{}}{{}}}
\bibcite{memmesheimer2014learning}{{20}{}{{}}{{}}}
\bibcite{mohemmed2012span}{{21}{}{{}}{{}}}
\bibcite{mohemmed2013training}{{22}{}{{}}{{}}}
\bibcite{nicola2016supervised}{{23}{}{{}}{{}}}
\bibcite{ohno1998effects}{{24}{}{{}}{{}}}
\bibcite{pfister2006optimal}{{25}{}{{}}{{}}}
\bibcite{pipaextended}{{26}{}{{}}{{}}}
\bibcite{ponulak2006supervised}{{27}{}{{}}{{}}}
\bibcite{ponulak2010supervised}{{28}{}{{}}{{}}}
\bibcite{ponulak2006generalization}{{29}{}{{}}{{}}}
\bibcite{pyle2018model}{{30}{}{{}}{{}}}
\bibcite{schnell2018neural}{{31}{}{{}}{{}}}
\bibcite{sussillo2009generating}{{32}{}{{}}{{}}}
\bibcite{tanaka2019recent}{{33}{}{{}}{{}}}
\bibcite{triefenbach2014large}{{34}{}{{}}{{}}}
\bibcite{triefenbach2010phoneme}{{35}{}{{}}{{}}}
\bibcite{vapnikn}{{36}{}{{}}{{}}}
\bibcite{wojcik2012electrical}{{37}{}{{}}{{}}}
\bibcite{wojcik2007liquid}{{38}{}{{}}{{}}}
\bibcite{zhang2015digital}{{39}{}{{}}{{}}}
\bibcite{zhao2018nonlinear}{{40}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
