%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[letterpaper, 10 pt, conference]{ieeeconf}  % Comment this line out
                                                          % if you need a4paper
%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4
                                                          % paper

\IEEEoverridecommandlockouts                              % This command is only
                                                          % needed if you want to
                                                          % use the \thanks command
\overrideIEEEmargins
% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document



% The following packages can be found on http:\\www.ctan.org
%\usepackage{graphics} % for pdf, bitmapped graphics files
%\usepackage{epsfig} % for postscript graphics files
%\usepackage{mathptmx} % assumes new font selection scheme installed
%\usepackage{times} % assumes new font selection scheme installed
%\usepackage{amsmath} % assumes amsmath package installed
%\usepackage{amssymb}  % assumes amsmath package installed

\title{\LARGE \bf
Spiking Neural Network for Speech Intonation Modelling
}

%\author{ \parbox{3 in}{\centering Huibert Kwakernaak*
%         \thanks{*Use the $\backslash$thanks command to put information here}\\
%         Faculty of Electrical Engineering, Mathematics and Computer Science\\
%         University of Twente\\
%         7500 AE Enschede, The Netherlands\\
%         {\tt\small h.kwakernaak@autsubmit.com}}
%         \hspace*{ 0.5 in}
%         \parbox{3 in}{ \centering Pradeep Misra**
%         \thanks{**The footnote marks may be inserted manually}\\
%        Department of Electrical Engineering \\
%         Wright State University\\
%         Dayton, OH 45435, USA\\
%         {\tt\small pmisra@cs.wright.edu}}
%}

\author{\textit{Lo\"ic Jeanningros, Philip N. Garner} \\
\\
Idiap Research Institute, Martigny, Switzerland% <-this % stops a space
%\thanks{$^{1}$Idiap Research Institute, Martigny, Switzerland
%        {}}%
%\thanks{$^{2}$Ecole Polytechnique F\'ed\'erale de Lausanne (EPFL), Switzerland
%        {}}%
}


\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

abstract

\end{abstract}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
Intonation is a prosodic feature of speech that carries non-linguistic information such as emphasis and emotion. As a distorded pitch can change the meaning of a sentence, or can reveal the speaker's emotional state, a good model of intonation is crucial for speech-to-speech translation systems that intend to transfer paralinguistics between languages.

In previous work with colleagues \cite{honnet2015atom}, we investiguated a physiologically plausible intonation ($F0$) model based on the Command-Response model of Fujisaki \cite{fujisaki1998command}. We presented a Generalized CR intonation contour using a matching pursuit algorithm \cite{mallat1993matching}. 

The task to perform then consists of learning temporal sequences of spikes, i.e. spike trains. Hence, we propose to resolve that learning task directly with a Spiking Neural Network (SNN) model.


Most important problem of supervised learning for SNN is binary character of of spiking neurons \cite{gavrilov2016methods}. No obvious differentiable error function can be backpropagated with gradient techniques. 
SpikeProp algorithm \cite{bohte2002error} employed difference between desirable and actual time of output spike as error but does not enable learning patterns composed of more than one spike. 
A supervised spike-based learning algorithm \cite{pfister2006optimal} that optimizes the likelihood of postsynaptic firing by gradient ascent allows to learn few spikes, but it is hard to estimate a potential to learn complex spike trains.
A gradient descent technique \cite{huh2018gradient} allows to learn spike trains but it breaks the all-or-none nature of synaptic currents.

Nevertheless, reservoir computing is a new trend of understanding training that has been started with Liquid State Machine (LSM) \cite{maass2002real} for the spike-based version. The basic idea behind reservoir computing is that, as long as an Recurrent Neural Network (RNN) possesses certain generic properties, supervised adaptation of all interconnection weights is not necessary, and only training a memoryless supervised readout from it is enough to obtain excellent performance in many tasks \cite{lukovsevivcius2012reservoir}.

The LSM is a task-independent high-dimensional network based neocortex microcircuits observation. The first component of a LSM is a filter, the liquid itself, outputs of that filter called the liquid state. The liquid state has only one attractor: the resting state. Perturbed states of the liquid represent present and past inputs. It has proven to have universal computational power and universal analog fading memory.

The second component of an LSM is a memoryless readout map that is trained to exctract information from the liquid state. Two similar learning rules are used in this purpose, ReSuMe \cite{ponulak2010supervised, ponulak2006supervised} and SPAN \cite{mohemmed2012span, mohemmed2013training}.

Reservoir computing has never been used for speech synthesis. Moreover, learning rules used here are suited for learning complex spike trains, but it is not obvious wether such algorithm are capable of generalization, able to predict unseen samples dynamic.



SNN has proved itself adequate for a number of computation and engineering problems, It is considered as a suitable tool to perform temporal pattern recognition and real-time computation \cite{mohemmed2012span}.

Due to the ability of the method to operate online and due to its fast convergence, the method is suitable for real-life applications. SNN trained with ReSuMe become efficient neurocontrollers for movement generation and control \cite{ponulak2010supervised}.



\addtolength{\textheight}{-12cm}   % This command serves to balance the column lengths
                                  % on the last page of the document manually. It shortens
                                  % the textheight of the last page by a suitable amount.
                                  % This command does not take effect until the next page
                                  % so it should come on the page before the last. Make
                                  % sure that you do not shorten the textheight too much.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{APPENDIX}


\section*{ACKNOWLEDGMENT}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\bibliographystyle{plain}
\bibliography{biblio}


\end{document}
